# file: .env.example
# Point the client at your local runner:
# Ollama default (desktop):
BASE_URL=http://localhost:11434/v1
# vLLM example (desktop):
# BASE_URL=http://localhost:8000/v1

MODEL_NAME=llama3.1:8b
FETCH_MAX_PER_TURN=4
FETCH_TIMEOUT_SEC=15